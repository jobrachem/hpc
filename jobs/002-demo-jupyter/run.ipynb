{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Demo Notebook\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "engine: jupyter\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: Variables that are general notebook settings that usually do not need to be\n",
        "changed by a user are written in CAPSLOCK. Only change them if you know what you\n",
        "are doing.\n",
        "\n",
        "## Parameters code block\n",
        "\n",
        "This code block usually does not need to be touched. It just extracts the parameters\n",
        "passed to the notebook.\n",
        "\n",
        "The `JOB_TESTING` flag can be used within this notebook to encode decisions that\n",
        "reduce runtime to make testing easier.\n",
        "\n",
        "Note that, while the jobdir can be discovered automatically when using the knitr\n",
        "engine, I have not found a way to do that when using the jupyter engine. So this\n",
        "part has to be manually adjusted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "JOB_DIR: str = \"jobs/002-demo-jupyter\"  # <- UPDATE THIS TO YOUR JOBDIR\n",
        "JOB_ROW: int = 0\n",
        "JOB_TESTING: bool = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "### Print Python executable\n",
        "\n",
        "This code block prints the Python executable in order to make debugging easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: print-python-executable\n",
        "import sys\n",
        "\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print current working directory\n",
        "\n",
        "Like printing the Python executable, this is mainly for debugging and should be executed at the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: print-working-directory\n",
        "from pathlib import Path\n",
        "\n",
        "print(Path.cwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries\n",
        "\n",
        "This codeblock import general utility libraries for this notebook.\n",
        "This is usually not the optimal place for model-specific dependencies.\n",
        "They are placed in the model section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: general-imports\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Process parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "JOB_PATH = Path(JOB_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: load-parameters-dataframe\n",
        "PARAMS = pd.read_csv(JOB_PATH / \"params.csv\").iloc[JOB_ROW, :]\n",
        "print(PARAMS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set identifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: create-identifier\n",
        "now = datetime.now().strftime(\"%Y-%m-%d-%H%M\")\n",
        "JOB_IDENTIFIER = JOB_PATH.name + \"-\" + f\"{JOB_ROW:04d}\" + \"-\" + now\n",
        "PARAMS[\"job\"] = JOB_PATH.name\n",
        "PARAMS[\"run\"] = JOB_IDENTIFIER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIR_LOG = JOB_PATH / \"log\"\n",
        "DIR_OUT = JOB_PATH / \"out\"\n",
        "DIR_FIN = JOB_PATH / \"finished\"\n",
        "\n",
        "if JOB_TESTING:\n",
        "    DIR_OUT = JOB_PATH / \"out-test\"\n",
        "\n",
        "DIR_LOG.mkdir(exist_ok=True)\n",
        "DIR_OUT.mkdir(exist_ok=True)\n",
        "DIR_FIN.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next code block makes sure that finished jobs are not run again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FINFILE = DIR_FIN / str(JOB_ROW)\n",
        "\n",
        "if FINFILE.exists() and not JOB_TESTING:\n",
        "    raise RuntimeError(\n",
        "        f\"Row {JOB_ROW} of job '{JOB_PATH.name}' is already finished. \"\n",
        "        \"To run this job again, you need to delete the file \"\n",
        "        f\"{str(JOB_PATH / 'finished' / str(JOB_ROW))}.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize logger\n",
        "\n",
        "Initializing a logger is standard practice in any script. Logging messages help you\n",
        "to be confident that your code is running as expected or to debug problems if necessary.\n",
        "\n",
        "Note that the logger will continue to append output to the log files, so if you have many runs and never clean them up, they will grow very large. So you should make sure that this does not happen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: initialize-logger\n",
        "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "handler = logging.FileHandler(filename=DIR_LOG / f\"run-{JOB_ROW:04d}.log\")\n",
        "handler.setLevel(logging.INFO)\n",
        "handler.setFormatter(formatter)\n",
        "\n",
        "stream_handler = logging.StreamHandler()\n",
        "stream_handler.setLevel(logging.INFO)\n",
        "handler.setFormatter(formatter)\n",
        "\n",
        "logger = logging.getLogger(str(JOB_PATH.name))\n",
        "logger.addHandler(handler)\n",
        "logger.addHandler(stream_handler)\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.info(f\"Job started: \\t{JOB_IDENTIFIER} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Code\n",
        "\n",
        "This is where your serious model code starts. This notebook includes only some dummy code for testing.\n",
        "\n",
        "### Model imports\n",
        "\n",
        "Note that some libraries are imported here. I think for these notebooks, it is good practice to import the libraries that are specific to your model here, to keep them separate from the libraries that are generally imported for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: model-imports\n",
        "import numpy as np\n",
        "import plotnine as p9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: data-generation\n",
        "rng = np.random.default_rng(JOB_ROW)\n",
        "\n",
        "n = 100\n",
        "b0 = 1.0\n",
        "b1 = 1.5\n",
        "x = rng.uniform(-2.0, 2.0, size=n)\n",
        "X = np.c_[np.ones_like(x), x]\n",
        "y = X @ np.r_[b0, b1] + rng.normal(size=n)\n",
        "\n",
        "p9.qplot(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: model-fitting\n",
        "beta_estimated = np.linalg.inv((X.T @ X)) @ X.T @ y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results dictionary\n",
        "\n",
        "By initializing the results dictionary like done below, i.e. by initializing it\n",
        "from the `PARAMS` object,\n",
        "you ensure that all necessary information about this job is saved,\n",
        "most importantly the job name, the job row (the row of params.csv\n",
        "that was used), and the job identifier. It also includes all parameter settings from the row of params.csv used for this run.\n",
        "This is a little wasteful in\n",
        "terms of file size for the results objects, because, strictly speaking,\n",
        "it would be sufficient to save the job name and job row; the parameter\n",
        "values can be retrieved from params.csv with this information. Doing it\n",
        "like it is coded here saves you the effort of merging. If file size becomes\n",
        "an issue, you may want to consider switching to the more sparse representation.\n",
        "Just always be careful to ensure that you will be able to identify the exact\n",
        "run conditions of each job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: results\n",
        "results = PARAMS.to_dict()\n",
        "\n",
        "results[\"b0_bias\"] = b0 - beta_estimated[0]\n",
        "results[\"b1_bias\"] = b1 - beta_estimated[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results\n",
        "\n",
        "It is up to you how exactly to save your outputs. I have had good experiences with creating one dedicated directory for each type of output dataframe that I save. In this demo, this is only one. In any case, make sure that each output dataframe contains the necessary information about the parameters used to create it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: save-results\n",
        "(DIR_OUT / \"results\").mkdir(exist_ok=True)\n",
        "\n",
        "results = pd.DataFrame(results, index=pd.Index([0]))\n",
        "results.to_csv(\n",
        "    DIR_OUT / \"results\" / f\"results-row{JOB_ROW:04d}.csv\",\n",
        "    index=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mark Job as Finished"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | label: mark-finished\n",
        "if not JOB_TESTING:\n",
        "    FINFILE.touch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
