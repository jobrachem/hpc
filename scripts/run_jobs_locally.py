"""
Runs jobs locally in sequence.

If parallelization is desired, the handling of finished runs has to be refactored.
The current logic relies on sequential execution for avoiding re-running finished
runs.

For parallelization, another issue that would need to be addressed is the
name clashes of temporary files generated by quarto when rendering.
This issue is solved for the HPC executing, but not for local execution
(although there is nothing that in principle would prevent us from solving
it).

This file should be executed via the command line::

    python scripts/run_jobs_locally.py
"""

from pathlib import Path
from subprocess import run

import pandas as pd

# --------------------------------------------------------------------------------------
# Update your settings here
# --------------------------------------------------------------------------------------
JOB_PREFIXES = [
    "001",
]
SAVE_RENDERED_NOTEBOOK = False
TESTING = False

# --------------------------------------------------------------------------------------
# The following code usually does not need to be touched
# --------------------------------------------------------------------------------------
JOBS = Path.cwd() / "jobs"


def run_one_job(prefix: str):
    job = [d for d in JOBS.iterdir() if d.name.startswith(prefix)][0]
    if (job / "finished").exists():
        finished = [int(fin.name) for fin in (job / "finished").iterdir()]
    else:
        finished = []

    params = pd.read_csv(job / "params.csv")
    for i in range(params.shape[0]):
        if i in finished:
            print(f"Skipping {i}: It is already finished.")
            continue

        job_row = i
        # output_dir = f"_output/jobs/{job.name}/run-{job_row:04d}"
        logfile = f"{job / 'log'}/run-{job_row:04d}.log"
        command = [
            "quarto",
            "render",
            str((job / "run.qmd")),
            "--output",
            "-",
            "--to",
            "gfm",
            # "--output-dir",
            # output_dir,
            "-P",
            f"JOB_ROW:{job_row}",
            "-P",
            f'JOB_DIR:"{str(job)}"',
            "-P",
            "JOB_TESTING:False",
        ]
        if not Path(logfile).exists():
            Path(logfile).parent.mkdir(exist_ok=True)
            Path(logfile).touch()

        with open(logfile, "a") as log:
            run(command, stdout=log, stderr=log, check=True)


if __name__ == "__main__":
    for prefix in JOB_PREFIXES:
        run_one_job(prefix)
